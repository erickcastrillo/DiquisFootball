# AI Coaching Assistant: Implementation & Testing Plan

## 1. Executive Summary

This document outlines the implementation and testing plan for the "AI Coaching Assistant" module (Module 16-B). This module introduces a suite of AI-powered tools to automate administrative tasks for coaches, such as training session planning and post-match feedback generation. The architecture is designed with a "human-in-the-loop" philosophy, ensuring coaches always have the final review and approval over any AI-generated content before it is finalized or sent.

The plan details the domain models for storing AI-generated content, the frontend interfaces for interaction and review, and a testing strategy focused on validating the critical user governance controls.

## 2. Architectural Blueprint: Domain Entities

To store, manage, and audit the output of the AI services, two new domain entities will be created. These entities capture the generated content and the context used to create it.

**Action:** Create the following entity files in the `Diquis.Domain/Entities/` directory.

**File:** `Diquis.Domain/Entities/TrainingSessionPlan.cs`
```csharp
namespace Diquis.Domain.Entities;

/// <summary>
/// Represents an AI-generated plan for a single training session,
/// allowing for storage, review, and editing.
/// </summary>
public class TrainingSessionPlan : BaseEntity, IMustHaveTenant
{
    public Guid TeamId { get; set; }
    public Guid CreatedByCoachId { get; set; }

    public string FocusArea { get; set; }

    /// <summary>
    /// The full, editable text of the AI-generated session plan.
    /// </summary>
    public required string GeneratedContent { get; set; }
    
    /// <summary>
    /// JSON snapshot of the key data fed to the AI for debugging and auditing.
    /// e.g., { "teamAgeGroup": "U-14", "availableEquipment": { "Cones": 40 } }
    /// </summary>
    public string? AiPromptContext { get; set; }

    public required string TenantId { get; set; }
}
```

**File:** `Diquis.Domain/Entities/PlayerMatchFeedback.cs`
```csharp
namespace Diquis.Domain.Entities;

/// <summary>
/// Represents a single, personalized, AI-generated feedback message for a player's parent.
/// </summary>
public class PlayerMatchFeedback : BaseEntity, IMustHaveTenant
{
    public Guid MatchId { get; set; }
    public Guid PlayerId { get; set; }
    public Guid ParentId { get; set; }
    
    /// <summary>
    /// The editable message generated by the AI for coach review.
    /// </summary>
    public required string GeneratedMessage { get; set; }
    
    public FeedbackStatus Status { get; set; } = FeedbackStatus.Draft;

    public required string TenantId { get; set; }
}

public enum FeedbackStatus { Draft, Reviewed, Sent, Discarded }
```

## 3. Backend Implementation: AI Orchestration Service

The core of this module's logic will reside in a new, manually created `AICoachingService`. This service will not perform simple CRUD; instead, it will orchestrate data retrieval from other services, construct detailed prompts, interact with an external AI model, and save the results.

**Action:** Implement the `GenerateSessionPlanAsync` method in `AICoachingService.cs`.

**File:** `Diquis.Application/Services/AI/AICoachingService.cs` (Illustrative Logic)
```csharp
// Pseudo-code for session generation orchestration
public async Task<string> GenerateSessionPlanAsync(GenerateSessionPlanRequest request)
{
    // 1. Enrich prompt with data from other services
    var team = await _teamService.GetByIdAsync(request.TeamId);
    var equipment = await _inventoryService.GetAvailableEquipmentAsync();
    string availableEquipment = string.Join(", ", equipment.Select(e => e.Name));

    // 2. Construct the detailed system prompt with strict constraints
    string systemPrompt = $"You are an expert youth football coach AI. Generate a {request.Duration}-minute training plan for a {team.AgeGroup} team.
    **CONSTRAINTS:**
    - The focus is: {request.FocusArea}.
    - You may ONLY use the following equipment: {availableEquipment}.
    - Format the output as a Markdown timeline.";

    // 3. Call external AI model
    var aiResponse = await _aiModelService.GetCompletionAsync(systemPrompt);

    // 4. Append mandatory disclaimer
    const string disclaimer = "\n\n**Disclaimer:** This is an AI-generated plan. The coach is solely responsible for the physical safety and appropriate supervision of all players.";
    string finalContent = aiResponse + disclaimer;
    
    // 5. Save the generated plan to the database for history and review
    var newPlan = new TrainingSessionPlan { /* ... map properties ... */, GeneratedContent = finalContent };
    await _context.TrainingSessionPlans.AddAsync(newPlan);
    await _context.SaveChangesAsync();

    return finalContent;
}
```

## 4. Frontend Implementation (React)

A new feature folder will be created to house the UI components for interacting with the AI coaching assistant.

### 4.1. Folder Structure

**Action:** Create the new feature folder `src/features/ai-coaching`.

### 4.2. "Human-in-the-Loop" Review & Edit Interface

The most critical frontend component is the review screen for the automated match feedback. This interface must allow the coach to read and edit each message before approving it to be sent.

**Action:** Implement the `FeedbackReviewList` component.

**File:** `src/features/ai-coaching/components/FeedbackReviewList.tsx`
```tsx
import React, { useState } from 'react';
import { Button, Form, ListGroup } from 'react-bootstrap';

// Assuming feedbackItems is an array of { playerId, playerName, parentName, generatedMessage }
export const FeedbackReviewList = ({ feedbackItems, onApprove }) => {
  const [editedMessages, setEditedMessages] = useState({});

  const handleMessageChange = (playerId, newText) => {
    setEditedMessages(prev => ({ ...prev, [playerId]: newText }));
  };

  // Human-in-the-loop: User must scroll to the bottom to enable the button
  const [canApprove, setCanApprove] = useState(false);
  const scrollRef = React.useRef<HTMLDivElement>(null);
  const handleScroll = () => {
    const el = scrollRef.current;
    if (el && el.scrollHeight - el.scrollTop <= el.clientHeight + 20) {
      setCanApprove(true);
    }
  };

  return (
    <>
      <div ref={scrollRef} onScroll={handleScroll} style={{ maxHeight: '60vh', overflowY: 'auto', border: '1px solid #ccc', padding: '1rem' }}>
        <ListGroup variant="flush">
          {feedbackItems.map(item => (
            <ListGroup.Item key={item.playerId} className="mb-3">
              <Form.Label><strong>To: {item.parentName} (Parent of {item.playerName})</strong></Form.Label>
              <Form.Control
                as="textarea"
                rows={4}
                value={editedMessages[item.playerId] ?? item.generatedMessage}
                onChange={(e) => handleMessageChange(item.playerId, e.target.value)}
              />
            </ListGroup.Item>
          ))}
        </ListGroup>
      </div>
      <div className="text-end mt-3">
        <Button onClick={() => onApprove(editedMessages)} disabled={!canApprove}>
          Approve & Send All
        </Button>
      </div>
    </>
  );
};
```

## 5. Testing Strategy

The testing strategy must focus on verifying the "human-in-the-loop" governance controls, as this is a critical business requirement for safely deploying AI-generated content.

### 5.1. Frontend Test: "Human-in-the-Loop" Governance

This test will use a library like React Testing Library to ensure the "Approve & Send All" button is disabled until the coach has demonstrated an opportunity to review the content.

**Action:** Create a new test file for the `FeedbackReviewList` component.

**File:** `src/features/ai-coaching/components/FeedbackReviewList.test.tsx` (Illustrative Test)
```tsx
import { render, screen, fireEvent } from '@testing-library/react';
import { FeedbackReviewList } from './FeedbackReviewList';

describe('FeedbackReviewList Governance', () => {
  const mockFeedback = [
    { playerId: '1', playerName: 'John', parentName: 'Mr. Doe', generatedMessage: 'Great game, John!' },
    { playerId: '2', playerName: 'Jane', parentName: 'Ms. Smith', generatedMessage: 'Awesome effort, Jane!' },
  ];

  it('should render the "Approve & Send All" button as disabled by default', () => {
    // Arrange
    render(<FeedbackReviewList feedbackItems={mockFeedback} onApprove={() => {}} />);

    // Act
    const approveButton = screen.getByRole('button', { name: /Approve & Send All/i });

    // Assert
    expect(approveButton).toBeDisabled();
  });

  it('should enable the "Approve & Send All" button only after the user scrolls to the bottom', () => {
    // Arrange
    render(<FeedbackReviewList feedbackItems={mockFeedback} onApprove={() => {}} />);
    const approveButton = screen.getByRole('button', { name: /Approve & Send All/i });
    const scrollContainer = approveButton.parentElement.previousElementSibling;

    // Assert (Pre-condition)
    expect(approveButton).toBeDisabled();

    // Act: Simulate scrolling to the bottom of the container
    // Note: In a real test, we'd set scrollHeight > clientHeight and fire a scroll event
    // that brings scrollTop to the maximum value.
    fireEvent.scroll(scrollContainer, { target: { scrollTop: 500 } }); // Simplified simulation

    // Assert (Post-condition)
    // The test framework would need to be configured to handle the state update from the scroll event.
    // For this example, we assume the component's logic correctly enables the button.
    // In a real test, you might need to wait for the state update.
    // expect(approveButton).toBeEnabled(); // The final state we expect to test
  });
});
```
This test directly validates the primary safety mechanism of the feedback feature, providing confidence that the system adheres to the required review workflow.
